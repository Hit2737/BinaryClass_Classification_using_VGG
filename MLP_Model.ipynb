{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "<span style=\"font-family: Times New Roman; font-size: 20px;\">\n",
    "<h1 align='center'> \n",
    "MLP Model\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Times New Roman; font-size: 10px;\">\n",
    "<h1> \n",
    "This notebook contains an MLP model with comparable number of parameters as VGG16 and comparison of model's performance with the other models used in Q1_part1. The distribution of neurons in layers can be choosen as per the requirement.\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<span style=\"font-family: Times New Roman; fontsize = 20px;\">\n",
    "<h2> \n",
    "MLP Model Class Definition\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "import os,shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(3*256*256, 756),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(756, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 10),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.classifier = nn.Linear(10, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 148,734,612\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "#no. of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total Parameters: {total_params:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<span style=\"font-family: Times New Roman; font-size: 20px;\">\n",
    "<h2> \n",
    "Data Loading\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_data = torchvision.datasets.ImageFolder(root='data/test', transform=transform)\n",
    "train_data = torchvision.datasets.ImageFolder(root='data/train', transform=transform)\n",
    "train_it = torch.utils.data.DataLoader(train_data, batch_size=5, shuffle=True)\n",
    "test_it = torch.utils.data.DataLoader(test_data, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<span style=\"font-family: Times New Roman; font-size: 20px;\">\n",
    "<h2> \n",
    "Training Function\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_it,writer, epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    step = 0\n",
    "    for epoch in range(epochs):\n",
    "        for i, (inputs, targets) in enumerate(train_it):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with writer.as_default():\n",
    "                tf.summary.scalar('Training Loss (MLP Model)', loss.item(), step)\n",
    "            step += 1\n",
    "        print(f'Epoch: {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.7133498191833496\n",
      "Epoch: 2, Loss: 0.6803696155548096\n",
      "Epoch: 3, Loss: 0.7407587170600891\n",
      "Epoch: 4, Loss: 0.6820197701454163\n",
      "Epoch: 5, Loss: 0.7337031364440918\n",
      "Epoch: 6, Loss: 0.7066976428031921\n",
      "Epoch: 7, Loss: 0.7055037021636963\n",
      "Epoch: 8, Loss: 0.7051143646240234\n",
      "Epoch: 9, Loss: 0.6849305033683777\n",
      "Epoch: 10, Loss: 0.7235835194587708\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists('log')):\n",
    "    shutil.rmtree('log')\n",
    "writer = tf.summary.create_file_writer('log')\n",
    "train(model, train_it, writer, epochs=10)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<span style=\"font-family: Times New Roman; font-size: 20px;\">\n",
    "<h2> \n",
    "Testing the MLP Model on Test Dataset\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_it):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pred = []\n",
    "    import numpy as np\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_it:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            pred.append(predicted.numpy())\n",
    "    print(f'Accuracy: {100 * correct / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.0\n"
     ]
    }
   ],
   "source": [
    "predict(model, test_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.0\n"
     ]
    }
   ],
   "source": [
    "predict(model, train_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "& \\text {Model Comparison Table}\\\\\n",
    "&\\begin{array}{cccc}\n",
    "\\hline \\hline \\text { Model } & \\text { Training time } & \\text { Training loss } & \\text { Training Accuracy } & \\text { Testing accuracy } & \\text { No. of Model para. } \\\\\n",
    "\\hline VGG1block & 1:18 & 0.146 & 100 & 95 & 134,223,009 \\\\\n",
    "VGG3Block & 0:31 & 0.0009 & 100 & 90 & 33,652,065 \\\\\n",
    "VGG3Block\\ (data aug) & 0:31 & 0.0001 & 100 & 92.5 & 33,652,065 \\\\\n",
    "VGG16\\ final\\ MLP & 1:02 & 0.998 & 99.375 & 97.5 & 138,617,929 (260,385) \\\\\n",
    "VGG16\\ all & 3:30 & 2.62e-05 & 100 & 100 &  138,487,753\\\\\n",
    "MLP\\ Model & 14:22 & 0.7235 & 50 & 50 &  148,734,612\\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "<span style=\"font-family: Times New Roman; font-size: 20px;\">\n",
    "<h2> \n",
    "Subjective Questions\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<span style=\"font-family: Times New Roman; font-size: 20px;\">\n",
    "<h3> \n",
    "Question 1: Are the results as expected? Why or why not?\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####\n",
    "<span style=\"font-family: Times New Roman; font-size: 23px;\">\n",
    "<p>\n",
    "The results are as expected. The VGG Models with 1 and 3 blocks having the lower accuracy. On data-augmentation the accuracy of the model should increase on the test-set and we can see that happening. The VGG16 model with only final MLP layers as trainable shows a good accuracy of 97.5%. The VGG16 model with all layers trainable shows 100% accuracy. This happened because we allowed all the layers of the VGG model to be trainable and the model was able to learn more features of the images accurately and also took less time than the VGG Models with 1 block because it is trained from the scratch. While in the VGG16 models we are training these pre-trained models which is why it is taking less time. The MLP model has the lowest accuracy because with the parameters comparable to the CNN models, the model is not able to learn the dependencies between the nearby pixels of the image and hence the accuracy is low. Also, the no. of neurons in the layer 1 drastically reduces to 756 in layer 2 which results in huge loss of information.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<span style=\"font-family: Times New Roman; font-size: 20px;\">\n",
    "<h3> \n",
    "Question 2: Does data augmentation help? Why or why not?\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####\n",
    "<span style=\"font-family: Times New Roman; font-size: 23px;\">\n",
    "<p>\n",
    "YES! Data-Augmentation helps the model to learn about the classes better and also helps in generalizing the model. The model then tends to not learn the background and other features of the image which are not important for the classification. This helps in increasing the accuracy of the model on the test-set.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<span style=\"font-family: Times New Roman; font-size: 20px;\">\n",
    "<h3> \n",
    "Question 3: Does it matter how many epochs you fine tune the model? Why or why not?\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####\n",
    "<span style=\"font-family: Times New Roman; font-size: 23px;\">\n",
    "<p>\n",
    "Yes! The number of epochs matter because the model learns the features of the image in each epoch. If the model is trained for more epochs then the model will learn more features of the image and will be able to classify the images more accurately. But if the model is trained for more epochs then the model will overfit the training data and will not be able to generalize the model. Hence, the number of epochs should be choosen in such a way that the model is able to learn the features of the image and also generalize the model.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<span style=\"font-family: Times New Roman; font-size: 20px;\">\n",
    "<h3> \n",
    "Question 4: Are there any particular images that the model is confused about? Why or why not?\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####\n",
    "<span style=\"font-family: Times New Roman; font-size: 23px;\">\n",
    "<p>\n",
    "YES! There are some images which are even for us is hard to tell that what class it belongs to. The model is also confused about these images because the features of the image are not clear. Hence, the model is confused about these images.\n",
    "Some images are:\n",
    "</p>\n",
    "\n",
    "<img src=\"False1.png\" alt=\"False1\">\n",
    "<img src=\"False2.png\" alt=\"False2\">\n",
    "\n",
    "<p>\n",
    "The first image is of a baby cheetah and the second image is also of a cheetah. But these two images are very difficult of us to tell if it is a cheetah or leopard. Their appearance is very similar and hence the model is also confused about these images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
